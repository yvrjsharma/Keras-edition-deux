{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPC/GbRdf5Hoytqk4vKZR8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvrjsharma/Keras-edition-deux/blob/main/Keras_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3svb98ujr_va"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "8dJDxAmFtYtQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#60k images which 28 by 28 pixels\n",
        "train_images.shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1n9Xk40t0AY",
        "outputId": "2089ef4c-d3bf-425b-ed1f-e4f877b05aab"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape,train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_eFVslkuTuB",
        "outputId": "fac6174c-0197-4710-e37d-1c2e04ff1b1b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000,), array([5, 0, 4, ..., 5, 6, 8], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCvl-AKYuwOx",
        "outputId": "d3717219-7ae3-4ad8-d246-0ccef519e686"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwmGj53bu1Oh",
        "outputId": "c6daefe6-e654-4c19-d8b4-f01e7db8f28e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build the network -"
      ],
      "metadata": {
        "id": "3SjEwRkkvN7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "QWsLUUlQvCyV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the network ready for training, we need three things to happen -\n",
        "1. A Loss function - Network will use this to measure its performance on training data, and thus to steer itself in the right direction.\n",
        "2. An Optimizer - A function or mechanism through which network will update itself based on the trainng data and loss function.\n",
        "3. Metrics - To monitor during training and testing. For example, accuracy or the fraction of images cofrectly classified.\n",
        "\n"
      ],
      "metadata": {
        "id": "DDwoNXxRV64B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compilation step\n",
        "network.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=\"rmsprop\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "KzroodkMvkJE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing the image data - convert to float\n",
        "train_images = train_images.reshape((60000, 28*28))\n",
        "train_images = train_images.astype(\"float32\")/255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28*28))\n",
        "test_images = test_images.astype(\"float32\")/255"
      ],
      "metadata": {
        "id": "RBXePYWdYrhL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding categorical variables in target\n",
        "from tensorflow import keras\n",
        "\n",
        "train_labels = keras.utils.to_categorical(train_labels)\n",
        "test_labels = keras.utils.to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "Jsvyiz1fZbPw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFyf5I_deZS8",
        "outputId": "2bc3432c-e739-4ac0-c2ca-7a085d643346"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_t2FLAEdLuq",
        "outputId": "e3022ac9-ef4c-4416-8f9e-1cc922fb731b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2605 - accuracy: 0.9236\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1034 - accuracy: 0.9687\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0683 - accuracy: 0.9794\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a6e126690>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The network has now learned to associate images with labels. Specifically, the netwrok layers have extracted representation out of the data fed into them. The final layer of Softmax will return an array of 10 probability scores summing upto 1 for every image in test set."
      ],
      "metadata": {
        "id": "kUkTmBVAgloH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "test_loss, test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElrAll_kcvm4",
        "outputId": "915fff30-aa54-42c7-e8ff-07929f824c9a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0720 - accuracy: 0.9785\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.07197816669940948, 0.9785000085830688)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are tensors? \n",
        "\n",
        "They are multi demiensional Numpy arrays used to store data. They are the building blocks of deep learning networks. A matrix for example, is a 2D tesnsor. So tensors can be defined as a generalization of matrices to an arbitrary number of dimensions. Also keep in mind that for tensors, a dimension is often referred as an axis. \n",
        "\n",
        "Vectors are nothing but 1D Tensors or just an array of numbers.\n",
        "\n",
        "Matrices are nothing but 2D Tensors. So they have two axes (rows, columns).\n",
        "\n",
        "3D Tensos means packing the the 2D metrices in another array. Similarly, if you pack this 3D Tensor into another array, you will get a 4D Tensor. Example of a 4D tensor would be an RGB image, a 5D tensor would be a video. A batch of 128 greyscale images with 256\\*256 size could be stored in a Tensor of (128,256,256,1) shape, while if it would have been RGB images, the tensor would looke like (128,256,256,3). For a video with 60 seconds of length, sampled at 4 frames per second, with size 144\\*256, and is RGB, the Tensor would be (240,144,256,3) and if there are 4 such sample clips - would be stored in a (4,240,144,256,3) or a 5D Tensor.\n",
        "\n",
        "Shape is nothing but how many dimensions are there along each axes."
      ],
      "metadata": {
        "id": "xuYwTXuYkO6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets also keep in mind that Deep Learning models don't process an entire dataset at once; rather, they break the data into small batches. "
      ],
      "metadata": {
        "id": "9xwOnj1U0Dcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a= np.array(12)\n",
        "b= np.array([1,2,3,4,5,6.,7,8,9])\n",
        "c= np.array([[1,2,3],[4,5,6], [7,8,9]])\n",
        "d= np.array([[[1.,2,3,11,999],[4,5,6,11,999], [7,8,9,11,999], [9,9,9,9,999]],\n",
        "             [[1,2,3,11,999],[4,5,6,11,999], [7,8,9,11,999], [9,9,9,9,999]],\n",
        "             [[1,2,3,11,999],[4,5,6,11,999], [7,8,9,11,999], [9,9,9,9,999]]])\n",
        "\n",
        "a.ndim, a.shape, a.dtype, a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyOoyIZill4g",
        "outputId": "1739d32a-f84e-46e8-9ac9-8015262a8105"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, (), dtype('int64'), array(12))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.ndim, b.shape,b.dtype, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxvshp9wuWGo",
        "outputId": "85ee2e7f-5b7a-4d6b-cc5e-dcaaf3aef102"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, (9,), dtype('float64'), array([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.ndim, c.shape, c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW7Bf_IduX-N",
        "outputId": "19f89bf9-2789-477a-b1a3-6666ed67d915"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, (3, 3), array([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d.ndim, d.shape,d.dtype, d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg1OCL7PubXN",
        "outputId": "520a6780-0080-4fb5-972c-c7bb1a91e921"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, (3, 4, 5), dtype('float64'), array([[[  1.,   2.,   3.,  11., 999.],\n",
              "         [  4.,   5.,   6.,  11., 999.],\n",
              "         [  7.,   8.,   9.,  11., 999.],\n",
              "         [  9.,   9.,   9.,   9., 999.]],\n",
              " \n",
              "        [[  1.,   2.,   3.,  11., 999.],\n",
              "         [  4.,   5.,   6.,  11., 999.],\n",
              "         [  7.,   8.,   9.,  11., 999.],\n",
              "         [  9.,   9.,   9.,   9., 999.]],\n",
              " \n",
              "        [[  1.,   2.,   3.,  11., 999.],\n",
              "         [  4.,   5.,   6.,  11., 999.],\n",
              "         [  7.,   8.,   9.,  11., 999.],\n",
              "         [  9.,   9.,   9.,   9., 999.]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor slicing, and reshaping\n",
        "digit = train_images[4].reshape(28,28)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(digit,cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ZgLYBY-hu4ES",
        "outputId": "32f6637f-e1cc-429c-d3c9-283cfd56661c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All transformations learned by deep neural networks cab be reduced to a handful of Tensor Operations applied to numeric data, example - additions, multiplying *etc.* \n",
        "\n",
        "Numpy helps in doing element-wise algebraic operations blazingly fast. Numpy uses BLAS or Basic Linear ALgebra Sub-programs to do all the heavy lifting in the background. BLAS does highly parallel and efficient tensor maniultaion and is implemented in low level languages like C or Fortran."
      ],
      "metadata": {
        "id": "ePV8ruinhAGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Broadcasting\n",
        "import numpy as np\n",
        "x = np.random.random((32,10))\n",
        "y = np.random.random((10,))"
      ],
      "metadata": {
        "id": "iQoDzDlxxTlo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.reshape(1,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUSDBchMZ08G",
        "outputId": "9261f0d9-7ba4-4d14-f631-390171563172"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.68064492, 0.05572055, 0.99493732, 0.89479167, 0.6766261 ,\n",
              "        0.00466041, 0.98610834, 0.24067052, 0.6750571 , 0.6318219 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x+y"
      ],
      "metadata": {
        "id": "VvOaBT75aQO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "dpCBaOCVZo9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "i0ABydNPZy9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.random((64,3,32,10))\n",
        "y = np.random.random((32,10))\n"
      ],
      "metadata": {
        "id": "DkamYbAIa_aa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z =  np.maximum(x,y)\n",
        "z"
      ],
      "metadata": {
        "id": "2pf-NpPrbMtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((300,100))\n",
        "y = np.transpose(x)\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVSOsC_ZgI8w",
        "outputId": "4bdc53d0-ba1d-4cb2-c476-4e34570503d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((300, 100), (100, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}